[{"authors":["admin"],"categories":null,"content":"\nHi!\nI\u0026rsquo;m a Senior Lecturer (≈ Assistant Professor) in the School of Computer Science at Tel Aviv University, where I lead the PLUS research group. My research interests are in the areas of computer security and privacy, machine learning, and human factors.\nPrior to joining Tel Aviv University, I spent roughly two years with VMware\u0026rsquo;s and NortonLifeLock\u0026rsquo;s research groups. I received my Ph.D. in Electrical and Computer Engineering from Carnegie Mellon University, where I was a member of CyLab and CUPS. I received my B.Sc. (via the Etgar/“Challenge” program) and M.Sc. (summa cum laude) degrees in Computer Science from the University of Haifa.\nIf you\u0026rsquo;re interested in joining our group, please do reach out.\n","date":1725148800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1725148800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Hi!\nI\u0026rsquo;m a Senior Lecturer (≈ Assistant Professor) in the School of Computer Science at Tel Aviv University, where I lead the PLUS research group. My research interests are in the areas of computer security and privacy, machine learning, and human factors.","tags":null,"title":"Mahmood Sharif","type":"authors"},{"authors":["yukiko-sawaya"],"categories":null,"content":"Website: https://www.researchgate.net/scientific-contributions/2046644129_Yukiko_Sawaya\n","date":1725148800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1725148800,"objectID":"36c0635eb95644b63181a0ec39cd421b","permalink":"/authors/yukiko-sawaya/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yukiko-sawaya/","section":"authors","summary":"Website: https://www.researchgate.net/scientific-contributions/2046644129_Yukiko_Sawaya","tags":null,"title":"Yukiko Sawaya","type":"authors"},{"authors":["keane-lucas"],"categories":null,"content":"Website: https://www.linkedin.com/in/keane-lucas/\n","date":1708905600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1708905600,"objectID":"8360faaf9393eb074a5bf801d52963f6","permalink":"/authors/keane-lucas/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/keane-lucas/","section":"authors","summary":"Website: https://www.linkedin.com/in/keane-lucas/","tags":null,"title":"Keane Lucas","type":"authors"},{"authors":["lujo-bauer"],"categories":null,"content":"Website: http://www.ece.cmu.edu/~lbauer/\n","date":1708905600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1708905600,"objectID":"847899d52e5c0707a8cf0720916cefdf","permalink":"/authors/lujo-bauer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/lujo-bauer/","section":"authors","summary":"Website: http://www.ece.cmu.edu/~lbauer/","tags":null,"title":"Lujo Bauer","type":"authors"},{"authors":["michael-k.-reiter"],"categories":null,"content":"Website: http://www.cs.unc.edu/~reiter/\n","date":1708905600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1708905600,"objectID":"02f60145845368542ff439e635aa15a2","permalink":"/authors/michael-k.-reiter/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/michael-k.-reiter/","section":"authors","summary":"Website: http://www.cs.unc.edu/~reiter/","tags":null,"title":"Michael K. Reiter","type":"authors"},{"authors":["weiran-lin"],"categories":null,"content":"Website: https://scholar.google.com/citations?user=oHxu2LsAAAAJ\u0026hl=en\n","date":1708905600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1708905600,"objectID":"8f8d73c474e09c66174f9e27cb99840c","permalink":"/authors/weiran-lin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/weiran-lin/","section":"authors","summary":"Website: https://scholar.google.com/citations?user=oHxu2LsAAAAJ\u0026hl=en","tags":null,"title":"Weiran Lin","type":"authors"},{"authors":["arnav-chakravarthy"],"categories":null,"content":"Website: https://www.linkedin.com/in/arnav-chakravarthy/\n","date":1666656000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1666656000,"objectID":"756604795c7d50399990bfa09fcfe6c1","permalink":"/authors/arnav-chakravarthy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/arnav-chakravarthy/","section":"authors","summary":"Website: https://www.linkedin.com/in/arnav-chakravarthy/","tags":null,"title":"Arnav Chakravarthy","type":"authors"},{"authors":["asmitha-rathis"],"categories":null,"content":"Website: https://www.linkedin.com/in/asmitha-rathis/\n","date":1666656000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1666656000,"objectID":"df8df8de3dd54dc9cdc96c9bdbffd345","permalink":"/authors/asmitha-rathis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/asmitha-rathis/","section":"authors","summary":"Website: https://www.linkedin.com/in/asmitha-rathis/","tags":null,"title":"Asmitha Rathis","type":"authors"},{"authors":["gagandeep-singh"],"categories":null,"content":"Website: https://ggndpsngh.github.io/\n","date":1666656000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1666656000,"objectID":"6caab62dca1dc2837e9b4adfe4966ff2","permalink":"/authors/gagandeep-singh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/gagandeep-singh/","section":"authors","summary":"Website: https://ggndpsngh.github.io/","tags":null,"title":"Gagandeep Singh","type":"authors"},{"authors":["marius-vilcu"],"categories":null,"content":"Website: https://www.linkedin.com/in/mariusvilcu/\n","date":1666656000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1666656000,"objectID":"d4c88aad1f8d774a1daf8223b34da2f0","permalink":"/authors/marius-vilcu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/marius-vilcu/","section":"authors","summary":"Website: https://www.linkedin.com/in/mariusvilcu/","tags":null,"title":"Marius Vilcu","type":"authors"},{"authors":["nina-narodytska"],"categories":null,"content":"Website: https://www.linkedin.com/in/nina-narodytska-7374392\n","date":1666656000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1666656000,"objectID":"1f3f2547057acd35a57261e3a3260246","permalink":"/authors/nina-narodytska/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/nina-narodytska/","section":"authors","summary":"Website: https://www.linkedin.com/in/nina-narodytska-7374392","tags":null,"title":"Nina Narodytska","type":"authors"},{"authors":["clark-barrett"],"categories":null,"content":"Website: http://theory.stanford.edu/~barrett/\n","date":1661990400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1661990400,"objectID":"9712e9b2fc2ba6627699f82fefd0061a","permalink":"/authors/clark-barrett/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/clark-barrett/","section":"authors","summary":"Website: http://theory.stanford.edu/~barrett/","tags":null,"title":"Clark Barrett","type":"authors"},{"authors":["haoze-wu"],"categories":null,"content":"Website: https://anwu1219.github.io/\n","date":1661990400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1661990400,"objectID":"93943a7322ec705723bdc0f171f8e06d","permalink":"/authors/haoze-wu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/haoze-wu/","section":"authors","summary":"Website: https://anwu1219.github.io/","tags":null,"title":"Haoze Wu","type":"authors"},{"authors":["daniel-kats"],"categories":null,"content":"Website: https://www.linkedin.com/in/daniel-kats-22568a65/\n","date":1661904000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1661904000,"objectID":"7c59c56c96cc51548435053418b53576","permalink":"/authors/daniel-kats/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/daniel-kats/","section":"authors","summary":"Website: https://www.linkedin.com/in/daniel-kats-22568a65/","tags":null,"title":"Daniel Kats","type":"authors"},{"authors":["saurabh-shintre"],"categories":null,"content":"Website: https://www.linkedin.com/in/saurabh-shintre-3b47465/\n","date":1613347200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1613347200,"objectID":"93f0edbe3de465c043328413e417e505","permalink":"/authors/saurabh-shintre/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/saurabh-shintre/","section":"authors","summary":"Website: https://www.linkedin.com/in/saurabh-shintre-3b47465/","tags":null,"title":"Saurabh Shintre","type":"authors"},{"authors":["anna-kawakami"],"categories":null,"content":"Website: https://www.linkedin.com/in/annakawakami/\n","date":1588291200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1588291200,"objectID":"409b317f95a470a73752a03e3eb0e04c","permalink":"/authors/anna-kawakami/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/anna-kawakami/","section":"authors","summary":"Website: https://www.linkedin.com/in/annakawakami/","tags":null,"title":"Anna Kawakami","type":"authors"},{"authors":["anupam-das"],"categories":null,"content":"Website: https://anupamdas.org/\n","date":1588291200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1588291200,"objectID":"2ea905b2151226e56f007cbd8cbc0e00","permalink":"/authors/anupam-das/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/anupam-das/","section":"authors","summary":"Website: https://anupamdas.org/","tags":null,"title":"Anupam Das","type":"authors"},{"authors":["camille-cobb"],"categories":null,"content":"Website: https://camillec.com/\n","date":1588291200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1588291200,"objectID":"49c2def0bdcd42eed61ad12b1419dd34","permalink":"/authors/camille-cobb/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/camille-cobb/","section":"authors","summary":"Website: https://camillec.com/","tags":null,"title":"Camille Cobb","type":"authors"},{"authors":["limin-jia"],"categories":null,"content":"Website: https://www.andrew.cmu.edu/user/liminjia/\n","date":1588291200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1588291200,"objectID":"9e27449df885c0b414c149c3bb6127c8","permalink":"/authors/limin-jia/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/limin-jia/","section":"authors","summary":"Website: https://www.andrew.cmu.edu/user/liminjia/","tags":null,"title":"Limin Jia","type":"authors"},{"authors":["milijana-surbatovich"],"categories":null,"content":"Website: https://msurbatovich.github.io/\n","date":1588291200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1588291200,"objectID":"d209a88f81ccf20629843fcd69db6c5a","permalink":"/authors/milijana-surbatovich/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/milijana-surbatovich/","section":"authors","summary":"Website: https://msurbatovich.github.io/","tags":null,"title":"Milijana Surbatovich","type":"authors"},{"authors":["acar-tamersoy"],"categories":null,"content":"Website: https://acartamersoy.github.io/\n","date":1585699200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1585699200,"objectID":"cf14db8673b77c3268324d959f96c720","permalink":"/authors/acar-tamersoy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/acar-tamersoy/","section":"authors","summary":"Website: https://acartamersoy.github.io/","tags":null,"title":"Acar Tamersoy","type":"authors"},{"authors":["amelia-nash"],"categories":null,"content":"Website: https://www.nortonlifelock.com/about/corporate-profile/research-labs/amelia-nash\n","date":1585699200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1585699200,"objectID":"9ffa7e214e139b51e4469cac981309d5","permalink":"/authors/amelia-nash/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/amelia-nash/","section":"authors","summary":"Website: https://www.nortonlifelock.com/about/corporate-profile/research-labs/amelia-nash","tags":null,"title":"Amelia Nash","type":"authors"},{"authors":["daniel-marino"],"categories":null,"content":"Website: https://www.linkedin.com/in/daniel-marino-657250123/\n","date":1585699200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1585699200,"objectID":"081f936e74ac4d4067159c2d5bb9cf63","permalink":"/authors/daniel-marino/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/daniel-marino/","section":"authors","summary":"Website: https://www.linkedin.com/in/daniel-marino-657250123/","tags":null,"title":"Daniel Marino","type":"authors"},{"authors":["kevin-a.-roundy"],"categories":null,"content":"Website: http://pages.cs.wisc.edu/~roundy/\n","date":1585699200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1585699200,"objectID":"5b4c512e6f0a5d1134e387a09e5e79c4","permalink":"/authors/kevin-a.-roundy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/kevin-a.-roundy/","section":"authors","summary":"Website: http://pages.cs.wisc.edu/~roundy/","tags":null,"title":"Kevin A. Roundy","type":"authors"},{"authors":["molly-davies"],"categories":null,"content":"Website: https://www.linkedin.com/in/molly-davies-lcsw-55090974/\n","date":1585699200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1585699200,"objectID":"1745c7c4149e2405e0f838ce3fb40ead","permalink":"/authors/molly-davies/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/molly-davies/","section":"authors","summary":"Website: https://www.linkedin.com/in/molly-davies-lcsw-55090974/","tags":null,"title":"Molly Davies","type":"authors"},{"authors":["sruti-bhagavatula"],"categories":null,"content":"Website: https://www.cs.cmu.edu/~sbhagava/\n","date":1559347200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1559347200,"objectID":"afcc9bf6ac669c36751e03c163c104fd","permalink":"/authors/sruti-bhagavatula/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/sruti-bhagavatula/","section":"authors","summary":"Website: https://www.cs.cmu.edu/~sbhagava/","tags":null,"title":"Sruti Bhagavatula","type":"authors"},{"authors":["christopher-gates"],"categories":null,"content":"Website: https://www.linkedin.com/in/csgates/\n","date":1556668800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1556668800,"objectID":"f4e192d313209cb64f52cb81b58913d0","permalink":"/authors/christopher-gates/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/christopher-gates/","section":"authors","summary":"Website: https://www.linkedin.com/in/csgates/","tags":null,"title":"Christopher Gates","type":"authors"},{"authors":["matteo-dellamico"],"categories":null,"content":"Website: https://www.linkedin.com/in/matteodellamico/\n","date":1556668800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1556668800,"objectID":"3143e103dcb8995982106809dc5a87f7","permalink":"/authors/matteo-dellamico/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/matteo-dellamico/","section":"authors","summary":"Website: https://www.linkedin.com/in/matteodellamico/","tags":null,"title":"Matteo Dellamico","type":"authors"},{"authors":["nicolas-christin"],"categories":null,"content":"Website: https://www.andrew.cmu.edu/user/nicolasc/\n","date":1556668800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1556668800,"objectID":"a026b8c46eaf9788c027a11736d2940b","permalink":"/authors/nicolas-christin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/nicolas-christin/","section":"authors","summary":"Website: https://www.andrew.cmu.edu/user/nicolasc/","tags":null,"title":"Nicolas Christin","type":"authors"},{"authors":["akira-yamada"],"categories":null,"content":"Website: https://www.linkedin.com/in/akira-yamada-737a352b/?originalSubdomain=jp\n","date":1538352000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1538352000,"objectID":"5ae815894ba0ebc4a3be2c2c838dba0f","permalink":"/authors/akira-yamada/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/akira-yamada/","section":"authors","summary":"Website: https://www.linkedin.com/in/akira-yamada-737a352b/?originalSubdomain=jp","tags":null,"title":"Akira Yamada","type":"authors"},{"authors":["ayumu-kubota"],"categories":null,"content":"Website: https://www.researchgate.net/scientific-contributions/2111415970_Ayumu_Kubota\n","date":1538352000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1538352000,"objectID":"ab8969abf02ddc01cdd2bedceb49ccb8","permalink":"/authors/ayumu-kubota/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/ayumu-kubota/","section":"authors","summary":"Website: https://www.researchgate.net/scientific-contributions/2111415970_Ayumu_Kubota","tags":null,"title":"Ayumu Kubota","type":"authors"},{"authors":["joshua-tan"],"categories":null,"content":"Website: https://joshktan.com/\n","date":1538352000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1538352000,"objectID":"a4447cab0a02031120932e0b1be59797","permalink":"/authors/joshua-tan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/joshua-tan/","section":"authors","summary":"Website: https://joshktan.com/","tags":null,"title":"Joshua Tan","type":"authors"},{"authors":["jumpei-urakawa"],"categories":null,"content":"Website: https://www.researchgate.net/scientific-contributions/2082710585_Jumpei_Urakawa\n","date":1538352000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1538352000,"objectID":"cf04bf10651860d2830c91478f6a5322","permalink":"/authors/jumpei-urakawa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/jumpei-urakawa/","section":"authors","summary":"Website: https://www.researchgate.net/scientific-contributions/2082710585_Jumpei_Urakawa","tags":null,"title":"Jumpei Urakawa","type":"authors"},{"authors":["matthias-beckerle"],"categories":null,"content":"Website: https://www.linkedin.com/in/matthiasbeckerle/\n","date":1538352000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1538352000,"objectID":"297131672ef8f34e048749058a45c46c","permalink":"/authors/matthias-beckerle/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/matthias-beckerle/","section":"authors","summary":"Website: https://www.linkedin.com/in/matthiasbeckerle/","tags":null,"title":"Matthias Beckerle","type":"authors"},{"authors":["michelle-mazurek"],"categories":null,"content":"Website: http://users.umiacs.umd.edu/~mmazurek/\n","date":1538352000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1538352000,"objectID":"0ae4c1c5374cb12252d1ba9f8115f044","permalink":"/authors/michelle-mazurek/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/michelle-mazurek/","section":"authors","summary":"Website: http://users.umiacs.umd.edu/~mmazurek/","tags":null,"title":"Michelle Mazurek","type":"authors"},{"authors":["william-melicher"],"categories":null,"content":"Website: https://www.linkedin.com/in/william-melicher-b2262b3a/\n","date":1517443200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1517443200,"objectID":"bc29b9d57780cdbc4a6cf1bef0dd4ba2","permalink":"/authors/william-melicher/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/william-melicher/","section":"authors","summary":"Website: https://www.linkedin.com/in/william-melicher-b2262b3a/","tags":null,"title":"William Melicher","type":"authors"},{"authors":["janos-szurdi"],"categories":null,"content":"Website: http://janos.szurdi.com/\n","date":1498867200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1498867200,"objectID":"fc6d59b3ae4a4dc18d5e695a31eeaf19","permalink":"/authors/janos-szurdi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/janos-szurdi/","section":"authors","summary":"Website: http://janos.szurdi.com/","tags":null,"title":"Janos Szurdi","type":"authors"},{"authors":["zachary-weinberg"],"categories":null,"content":"Website: https://www.owlfolio.org/\n","date":1498867200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1498867200,"objectID":"bf0abec04605f59441956d7943f40e50","permalink":"/authors/zachary-weinberg/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/zachary-weinberg/","section":"authors","summary":"Website: https://www.owlfolio.org/","tags":null,"title":"Zachary Weinberg","type":"authors"},{"authors":["akihiro-nakarai"],"categories":null,"content":"Website: https://dblp.uni-trier.de/pers/hd/n/Nakarai:Akihiro\n","date":1493596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1493596800,"objectID":"0b4be4bf4ccea63768e9e514eeac7cf0","permalink":"/authors/akihiro-nakarai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/akihiro-nakarai/","section":"authors","summary":"Website: https://dblp.uni-trier.de/pers/hd/n/Nakarai:Akihiro","tags":null,"title":"Akihiro Nakarai","type":"authors"},{"authors":["mihai-christodorescu"],"categories":null,"content":"Website: https://www.christodorescu.org/\n","date":1467331200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1467331200,"objectID":"3ac4078a1a3e5af5f60d916bc20b7015","permalink":"/authors/mihai-christodorescu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/mihai-christodorescu/","section":"authors","summary":"Website: https://www.christodorescu.org/","tags":null,"title":"Mihai Christodorescu","type":"authors"},{"authors":["pedro-g.-leon"],"categories":null,"content":"Website: https://dblp.org/pers/l/Leon:Pedro_Giovanni.html\n","date":1467331200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1467331200,"objectID":"3e5c08d756ec46d6e19673e36792ffde","permalink":"/authors/pedro-g.-leon/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/pedro-g.-leon/","section":"authors","summary":"Website: https://dblp.org/pers/l/Leon:Pedro_Giovanni.html","tags":null,"title":"Pedro G. Leon","type":"authors"},{"authors":["template"],"categories":null,"content":"Website: https://example.org\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"714f0324087ead84f928625a53508bfa","permalink":"/authors/template/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/template/","section":"authors","summary":"Website: https://example.org","tags":null,"title":"Template Author","type":"authors"},{"authors":["Yukiko Sawaya","Sarah Lu","Takamasa Isohara","Mahmood Sharif"],"categories":null,"content":"","date":1725148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1725148800,"objectID":"6cf8eb76cfc2cc7f57fc3b0b4d4ff97c","permalink":"/publication/usenix24-esbs/","publishdate":"2023-09-30T00:00:00Z","relpermalink":"/publication/usenix24-esbs/","section":"publication","summary":"Psychometric security scales can enable various crucial tasks (e.g., measuring changes in user behavior over time), but, unfortunately, they often fail to accurately predict actual user behavior. We hypothesize that one can enhance prediction accuracy via more comprehensive scales measuring a wider range of security-related factors. To test this hypothesis, we ran a series of four online studies with a total of 1,471 participants. First, we developed the extended security behavior scale (ESBS), a high-coverage scale containing substantially more items than prior ones, and collected responses to characterize its underlying structure. Then, we conducted a follow-up study to confirm ESBS’s structural validity and reliability. Finally, over the course of two studies, we elicited user responses to our scale and prior ones while measuring three security behaviors reflected by Internet browser data. Then, we constructed predictive machine-learning models and found that ESBS can predict these behaviors with statistically significantly higher accuracy than prior scales (6.17%–8.53% ROC AUC), thus supporting our hypothesis.","tags":["Source Themes"],"title":"A High Coverage Cybersecurity Scale Predictive of User Behavior","type":"publication"},{"authors":["Mahmood Sharif","Pubali Datta","Andy Riddle","Kim Westfall","Adam Bates","Vijay Ganti","Matthew Lentz","David Ott"],"categories":null,"content":"","date":1716163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716163200,"objectID":"5504d585108fc7851533c97bac0fd609","permalink":"/publication/oakland24-drsec/","publishdate":"2023-12-08T00:00:00Z","relpermalink":"/publication/oakland24-drsec/","section":"publication","summary":"The increasing complexity of attacks has given rise to varied security applications tackling profound tasks, ranging from alert triage to attack reconstruction. Yet, security products, such as Endpoint Detection and Response, bring together applications that are developed in isolation, trigger many false positives, miss actual attacks, and produce limited labels useful in supervised learning schemes. To address these challenges, we propose DrSec—a system employing self-supervised learning to pre-train foundation language models (LMs) that ingest event-sequence data and emit distributed representations for processes. Once pre-trained, the LMs can be adapted to solve different downstream tasks with limited to no supervision, helping unify the currently fractured application ecosystem. We trained DrSec with two LM types on a real-world dataset containing ∼91M processes and ∼2.55B events, and tested it in three application domains. We found that DrSec enables accurate, unsupervised process identification; outperforms leading methods on alert triage to reduce alert fatigue (e.g., 75.11% vs. ≤64.31% precision-recall area under curve); and accurately learns expert-developed rules, allowing tuning incident detectors to control false positives and negatives.","tags":["Source Themes"],"title":"DrSec: Flexible Distributed Representations for Efficient Endpoint Security","type":"publication"},{"authors":["Weiran Lin","Keane Lucas","Neo Eyal","Lujo Bauer","Michael K. Reiter","Mahmood Sharif"],"categories":null,"content":"","date":1708905600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708905600,"objectID":"9c98eece3f16ab3271b0f8bb8270ea08","permalink":"/publication/ndss24-gbr/","publishdate":"2023-09-30T00:00:00Z","relpermalink":"/publication/ndss24-gbr/","section":"publication","summary":"TBA.","tags":["Source Themes"],"title":"Group-based Robustness: A General Framework for Customized Robustness in the Real World","type":"publication"},{"authors":["Amit Cohen","Mahmood Sharif"],"categories":null,"content":"","date":1690848000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690848000,"objectID":"42b52c50bb8c3688eb2663c133a5a0c9","permalink":"/publication/esorics23-nir-attacks/","publishdate":"2023-08-18T00:00:00Z","relpermalink":"/publication/esorics23-nir-attacks/","section":"publication","summary":"Prior work showed that face-recognition systems ingesting RGB images captured via visible-light (VIS) cameras are susceptible to real-world evasion attacks. Face-recognition systems in near-infrared (NIR) are widely deployed for critical tasks (e.g., access control), and are hypothesized to be more secure due to the lower variability and dimensionality of NIR images compared to VIS ones. However, the actual robustness of NIR-based face recognition remains unknown. This work puts the hypothesis to the test by offering attacks well-suited for NIR-based face recognition and adapting them to facilitate physical realizability. The outcome of the attack is an adversarial accessory the adversary can wear to mislead NIR-based face-recognition systems. We tested the attack against six models, both defended and undefended, with varied numbers of subjects in the digital and physical domains. We found that face recognition in NIR is highly susceptible to real-world attacks. For example, ≥96.66% of physically realized attack attempts seeking arbitrary misclassification succeeded, including against defended models. Overall, our work highlights the need to defend NIR-based face recognition, especially when deployed in high-stakes domains.","tags":["Source Themes"],"title":"Accessorize in the Dark: A Security Analysis of Near-Infrared Face Recognition","type":"publication"},{"authors":["Keane Lucas","Samruddhi Pai","Weiran Lin","Lujo Bauer","Michael K. Reiter","Mahmood Sharif"],"categories":null,"content":"","date":1690848000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690848000,"objectID":"e2f86dbe7ccaca693a68f770b89bf0ca","permalink":"/publication/usenix23-malware-advtrain/","publishdate":"2022-12-18T00:00:00Z","relpermalink":"/publication/usenix23-malware-advtrain/","section":"publication","summary":"Machine learning (ML) models have shown promise in classifying raw executable files (binaries) as malicious or benign with high accuracy. This has led to the increasing influence of ML-based classification methods in academic and real-world malware detection, a critical tool in cybersecurity. However, previous work provoked caution by creating variants of malicious binaries, referred to as adversarial examples, that are transformed in a functionality-preserving way to evade detection. In this work, we investigate the effectiveness of using adversarial training methods to create malware-classification models that are more robust to some state-of-the-art attacks. To train our most robust models, we significantly increase the efficiency and scale of creating adversarial examples to make adversarial training practical, which has not been done before in raw-binary malware detectors. We then analyze the effects of varying the length of adversarial training, as well as analyze the effects of training with various types of attacks. We find that data augmentation does not deter state-of-the-art attacks, but that using a generic gradient-guided method, used in other discrete domains, does improve robustness. We also show that in most cases, models can be made more robust to malware-domain attacks by adversarially training them with lower-effort versions of the same attack. In the best case, we reduce one state-of-the-art attack’s success rate from 90% to 5%. We also find that training with some types of attacks can increase robustness to other types of attacks. Finally, we discuss insights gained from our results, and how they can be used to more effectively train robust malware detectors.","tags":["Source Themes"],"title":"Adversarial Training for Raw-Binary Malware Classifiers","type":"publication"},{"authors":["Arnav Chakravarthy","Nina Narodytska","Asmitha Rathis","Marius Vilcu","Mahmood Sharif","Gagandeep Singh"],"categories":null,"content":"","date":1666656000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666656000,"objectID":"649e062d86c527fccf388aa2c64ea402","permalink":"/publication/dmml22-rl-controllers/","publishdate":"2022-10-25T00:00:00Z","relpermalink":"/publication/dmml22-rl-controllers/","section":"publication","summary":"Reinforcement learning-based controllers (RL-controllers) in self-driving datacenters have evolved into complex dynamic systems that require continuous tuning to achieve higher performance than hand-crafted expert heuristics. The operating environment of these controllers poses additional challenges as it can often change significantly, thus the controllers must be adapted to new external conditions. To obtain trustworthy RL-controllers for self-driving datacenters, it is essential to guarantee that RL-controllers that are trained continuously in these changing environments behave according to the designer’s notions of reliability and correctness. Traditionally, RL-controllers are evaluated by comparing their reward function statistics. However, that does not capture all desired properties, e.g., stability, of the controller. In this work, we propose enhancing the evaluation criteria for RL-controllers with a set of novel metrics that quantify how well the controller performs with respect to user-defined properties. We leverage formal methods for computing our novel metrics. Thus, our work makes a step forward toward improving trustworthiness of RL-controllers. We show that these metrics are useful in evaluating a standalone controller or in comparing multiple controllers that achieve the same reward.","tags":["Source Themes"],"title":"Property-Driven Evaluation of RL-Controllers in Self-Driving Datacenters","type":"publication"},{"authors":["Haoze Wu","Clark Barrett","Mahmood Sharif","Nina Narodytska","Gagandeep Singh"],"categories":null,"content":"","date":1661990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661990400,"objectID":"632c4a23f3a675263232cc67bc18140a","permalink":"/publication/oopsla22-gnn-verify/","publishdate":"2022-09-01T00:00:00Z","relpermalink":"/publication/oopsla22-gnn-verify/","section":"publication","summary":"Recently, Graph Neural Networks (GNNs) have been applied for scheduling jobs over clusters, achieving better performance than hand-crafted heuristics. Despite their impressive performance, concerns remain over whether these GNN-based job schedulers meet users’ expectations about other important properties, such as strategy-proofness, sharing incentive, and stability. In this work, we consider formal verification of GNN-based job schedulers. We address several domain-specific challenges such as networks that are deeper and specifications that are richer than those encountered when verifying image and NLP classifiers. We develop vegas, the first general framework for verifying both single-step and multi-step properties of these schedulers based on carefully designed algorithms that combine abstractions, refinements, solvers, and proof transfer. Our experimental results show that vegas achieves significant speed-up when verifying important properties of a state-of-the-art GNN-based scheduler compared to previous methods.","tags":["Source Themes"],"title":"Scalable Verification of GNN-based Job Schedulers","type":"publication"},{"authors":["Daniel Kats","Mahmood Sharif"],"categories":null,"content":"","date":1661904000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661904000,"objectID":"5c5ca58cff9f863e2024fbafd8ea7a15","permalink":"/publication/hai22-bots/","publishdate":"2022-08-31T00:00:00Z","relpermalink":"/publication/hai22-bots/","section":"publication","summary":"Social bots—software agents controlling accounts on online social networks (OSNs)—have been employed for various malicious purposes, including spreading disinformation and scams. Understanding user perceptions of bots and ability to distinguish them from other accounts can inform mitigations. To this end, we conducted an online study with 297 users of seven OSNs to explore their mental models of bots and evaluate their ability to classify bots and non-bots correctly. We found that while some participants were aware of bots’ primary characteristics, others provided abstract descriptions or confused bots with other phenomena. Participants also struggled to classify accounts correctly (e.g., misclassifying \u003e50% of accounts) and were more likely to misclassify bots than non-bots. Furthermore, we observed that perceptions of bots had a significant effect on participants’ classification accuracy. For example, participants with abstract perceptions of bots were more likely to misclassify. Informed by our findings, we discuss directions for developing user-centered interventions against bots.","tags":["Source Themes"],"title":"\"I Have No Idea What a Social Bot Is\": On Users' Perceptions of Social Bots and Ability to Detect Them","type":"publication"},{"authors":["Weiran Lin","Keane Lucas","Lujo Bauer","Michael K. Reiter","Mahmood Sharif"],"categories":null,"content":"","date":1652572800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652572800,"objectID":"7e8510412fb5fa515ef194d442028425","permalink":"/publication/icml22-cgd/","publishdate":"2022-05-15T00:00:00Z","relpermalink":"/publication/icml22-cgd/","section":"publication","summary":"Minimal adversarial perturbations added to inputs have been shown to be effective at fooling deep neural networks. In this paper, we introduce several innovations that make white-box targeted attacks follow the intuition of the attacker's goal: to trick the model to assign a higher probability to the target class than to any other, while staying within a specified distance from the original input. First, we propose a new loss function that explicitly captures the goal of targeted attacks, in particular, by using the logits of all classes instead of just a subset, as is common. We show that Auto-PGD with this loss function finds more adversarial examples than it does with other commonly used loss functions. Second, we propose a new attack method that uses a further developed version of our loss function capturing both the misclassification objective and the $L_∞$ distance limit 𝝴. This new attack method is relatively 1.5--4.2% more successful on the CIFAR10 dataset and relatively 8.2--14.9% more successful on the ImageNet dataset, than the next best state-of-the-art attack. We confirm using statistical tests that our attack outperforms state-of-the-art attacks on different datasets and values of 𝝴 and against different defenses.","tags":["Source Themes"],"title":"Constrained Gradient Descent: A Powerful and Principled Evasion Attack Against Neural Networks","type":"publication"},{"authors":["Keane Lucas","Mahmood Sharif","Lujo Bauer","Michael K. Reiter","Saurabh Shintre"],"categories":null,"content":"","date":1613347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613347200,"objectID":"a7f61f040f4bca0de0125cc0eaf783b4","permalink":"/publication/asiaccs21-malware/","publishdate":"2021-02-15T00:00:00Z","relpermalink":"/publication/asiaccs21-malware/","section":"publication","summary":"Motivated by the transformative impact of deep neural networks (DNNs) in various domains, researchers and anti-virus vendors have proposed DNNs for malware detection from raw bytes that do not require manual feature engineering. In this work, we propose an attack that interweaves binary-diversification techniques and optimization frameworks to mislead such DNNs while preserving the functionality of binaries. Unlike prior attacks, ours manipulates instructions that are a functional part of the binary, which makes it particularly challenging to defend against. We evaluated our attack against three DNNs in white- and black-box settings, and found that it often achieved success rates near 100%. Moreover, we found that our attack can fool some commercial anti-viruses, in certain cases with a success rate of 85%. We explored several defenses, both new and old, and identified some that can foil over 80% of our evasion attempts. However, these defenses may still be susceptible to evasion by attacks, and so we advocate for augmenting malware-detection systems with methods that do not rely on machine learning.","tags":["Source Themes"],"title":"Malware Makeover: Breaking ML-based Static Analysis by Modifying Executable Bytes","type":"publication"},{"authors":["Camille Cobb","Milijana Surbatovich","Anna Kawakami","Mahmood Sharif","Lujo Bauer","Anupam Das","Limin Jia"],"categories":null,"content":"","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"d85d2c93ea9026460aacb0c295a06cc3","permalink":"/publication/soups20-ifttt/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/publication/soups20-ifttt/","section":"publication","summary":"Smart-home devices are becoming increasingly ubiquitous and interconnected with other devices and services, such as phones, fitness trackers, cars, and social media accounts. Built-in connections between these services are still emerging, but end-user-programming tools such as If-This-Then-That (IFTTT) have existed for almost a decade, allowing users to create rules (called applets in IFTTT) that dictate interactions between devices and services. Previous work found potential secrecy or integrity violations in many applets, but did so without examining how individual users interact with the service. In this work, we study the risks of real-world use of IFTTT by collecting and analyzing 732 applets installed by 28 participants and participants' responses to several survey questions. We found that significantly fewer applets than previously thought pose realistic secrecy or integrity risks to the users who install them. Perhaps consistently, participants were generally not concerned about potential harms, even when these were explained to them. However, examining participants' applets led us to identify several new types of privacy risks, which challenge some assumptions inherent in previous analyses that focus on secrecy and integrity risks. For example, we found that many applets involve monitoring incidental users: family, friends, and neighbors who may interact with someone else's smart-home devices, possibly without realizing it. We discuss what our findings imply for automatically identifying potentially harmful applets.","tags":["Source Themes"],"title":"How Risky Are Real Users' IFTTT Applets?","type":"publication"},{"authors":["Molly Davies","Daniel Marino","Amelia Nash","Kevin A. Roundy","Mahmood Sharif","Acar Tamersoy"],"categories":null,"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"7e01d5056ec6b7914647f4e537bcebc8","permalink":"/publication/chiw20-older-adults/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/publication/chiw20-older-adults/","section":"publication","summary":"Older adults are disproportionately affected by scams, many of which target them specifically. In this interactive demo, we present *Fraud Bingo*, an intervention designed by WISE \u0026 Healthy Aging Center in Southern California prior to 2012, that has been played by older adults throughout the United States. We also present the Scam Defender Obstacle Course (SDOC), an interactive web application that tests a user's ability to identify scams, and subsequently explains how to recognize the scams. SDOC is patterned after existing phishing-recognition training tools for working professionals. We present the results of running a workshop with 17 senior citizens, where we performed a controlled study that used SDOC to measure the effectiveness of Fraud Bingo. We outline the difficulties several participants had with completing SDOC, which indicate that tools like SDOC should be tailored to the needs of older adults. Additionally, we discuss how to adapt Fraud Bingo and SDOC for international audiences.","tags":["Source Themes"],"title":"Training Older Adults to Resist Scams with Fraud Bingo and Scam-Detection Challenges","type":"publication"},{"authors":["Mahmood Sharif","Lujo Bauer","Michael K. Reiter"],"categories":null,"content":"","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"5174668fd26da7e3d646efd3ec9ef797","permalink":"/publication/arxiv19-nml/","publishdate":"2019-12-01T00:00:00Z","relpermalink":"/publication/arxiv19-nml/","section":"publication","summary":"This paper proposes a new defense called $n$-ML against adversarial examples, i.e., inputs crafted by perturbing benign inputs by small amounts to induce misclassifications by classifiers.  Inspired by $n$-version programming, $n$-ML trains an ensemble of $n$ classifiers, and inputs are classified by a vote of the classifiers in the ensemble.  Unlike prior such approaches, however, the classifiers in the ensemble are trained specifically to classify adversarial examples differently, rendering it very difficult for an adversarial example to obtain enough votes to be misclassified.  We show that $n$-ML roughly retains the benign classification accuracies of state-of-the-art models on the MNIST, CIFAR10, and GTSRB datasets, while simultaneously defending against adversarial examples with better resilience than the best defenses known to date and, in most cases, with lower classification-time overhead.","tags":["Source Themes"],"title":"$n$-ML: Mitigating Adversarial Examples via Ensembles of Topologically Manipulated Classifiers","type":"publication"},{"authors":["Mahmood Sharif"],"categories":null,"content":"","date":1573430400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573430400,"objectID":"fd6914ecac593b5f2aae97f750b58292","permalink":"/publication/thesis19-phd-cmu-ece/","publishdate":"2019-11-11T00:00:00Z","relpermalink":"/publication/thesis19-phd-cmu-ece/","section":"publication","summary":"Prior work has shown that machine-learning algorithms are vulnerable to evasion by so-called adversarial examples. Nonetheless, the majority of the work on evasion attacks has mainly explored $L_p$-bounded perturbations that lead to misclassification. From a computer-security perspective, such attacks have limited practical implications. To fill the gap, we propose evasion attacks that satisfy *multiple objectives*, and show that these attacks pose a practical threat to computer systems. In particular, we demonstrate how to produce adversarial examples against state-of-the-art face-recognition and malware-detection systems that simultaneously satisfy multiple objectives (e.g., smoothness and robustness against changes in imaging conditions) to mislead the systems in practical settings. Against face recognition, we develop a systematic method to automatically generate attacks, which are realized through printing a pair of eyeglass frames. When worn by attackers, the eyeglasses allow them mislead face-recognition algorithms to evade recognition or impersonate other individuals. Against malware detection, we develop an attack that guides binary-diversification tools via optimization to transform binaries in a functionality preserving manner and mislead detection.\nThe attacks that we initially demonstrate achieve the desired objectives via ad hoc optimizations. We extend these attacks via a general framework to train a generator neural network to emit adversarial examples satisfying desired objectives. We demonstrate the ability of the proposed framework to accommodate a wide range of objectives, including imprecise ones difficult to model, in two application domains. Specifically, we demonstrate how to produce adversarial eyeglass frames to mislead face recognition with better robustness, inconspicuousness, and scalability than previous approaches, as well as a new attack to fool a handwritten-digit classifier.\nFinally, to protect computer-systems from adversarial examples, we propose $n$-ML---a novel defense that is inspired by $n$-version programming. $n$-ML trains an ensemble of $n$ classifiers, and classifies inputs by a vote. Unlike prior approaches, however, the classifiers are trained to classify adversarial examples differently than each other, rendering it very difficult for an adversarial example to obtain enough votes to be misclassified. In several application domains (including face and street-sign recognition), we show that $n$-ML roughly retains the benign classification accuracies of state-of-the-art models, while simultaneously defending against adversarial examples (produced by our framework, or $L_p$-based attacks) with better resilience than the best defenses known to date and, in most cases, with lower inference-time overhead.","tags":["Source Themes"],"title":"Practical Inference-Time Attacks Against Machine-Learning Systems and a Defense Against Them","type":"publication"},{"authors":["Mahmood Sharif","Sruti Bhagavatula","Lujo Bauer","Michael K. Reiter"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"f1e947c71f7b545823689ac0713e21c5","permalink":"/publication/tops19-adv-ml/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/publication/tops19-adv-ml/","section":"publication","summary":"Images perturbed subtly to be misclassified by neural networks, called *adversarial examples*, have emerged as a technically deep challenge and an important concern for several application domains.  Most research on adversarial examples takes as its only constraint that the perturbed images are similar to the originals.  However, real-world application of these ideas often requires the examples to satisfy additional objectives, which are typically enforced through custom modifications of the perturbation process.  In this paper, we propose *adversarial generative nets* (AGNs), a general methodology to train a *generator* neural network to emit adversarial examples satisfying desired objectives. We demonstrate the ability of AGNs to accommodate a wide range of objectives, including imprecise ones difficult to model, in two application domains.  In particular, we demonstrate *physical* adversarial examples---eyeglass frames designed to fool face recognition---with better robustness, inconspicuousness, and scalability than previous approaches, as well as a new attack to fool a handwritten-digit classifier.","tags":["Source Themes"],"title":"A General Framework for Adversarial Examples with Objectives","type":"publication"},{"authors":["Mahmood Sharif","Kevin A. Roundy","Matteo Dellamico","Christopher Gates","Daniel Kats","Lujo Bauer","Nicolas Christin"],"categories":null,"content":"","date":1556668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556668800,"objectID":"524bc41512d734d555269e97772c26bb","permalink":"/publication/chi19-customer-support/","publishdate":"2019-05-01T00:00:00Z","relpermalink":"/publication/chi19-customer-support/","section":"publication","summary":"Understanding users' perceptions of suspected computer-security problems can help us tailor technology to better protect users. To this end, we conducted a field study of users' perceptions using 189,272 problem descriptions sent to the customer-support desk of a large anti-virus vendor from 2015 to 2018. Using qualitative methods, we analyzed 650 problem descriptions to study the security issues users faced and the symptoms that led users to their own diagnoses. Subsequently, we investigated to what extent and for what types of issues user diagnoses matched those of experts. We found, for example, that users and experts were likely to agree for most issues, but not for attacks (e.g., malware infections), for which they agreed only in 44% of the cases. Our findings inform several user-security improvements, including how to automate interactions with users to resolve issues and to better communicate issues to users.","tags":["Source Themes"],"title":"A Field Study of Computer-Security Perceptions Using Anti-Virus Customer-Support Chats","type":"publication"},{"authors":["Joshua Tan","Mahmood Sharif","Sruti Bhagavatula","Matthias Beckerle","Lujo Bauer","Michelle Mazurek"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"23a8bf60344f1514a1a53c7ae9d0c30c","permalink":"/publication/wpes18-privacy-valuations/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/publication/wpes18-privacy-valuations/","section":"publication","summary":"To protect users' privacy, it is important to understand how they value personal information. Prior work identified how framing effects alter users' valuations and highlighted the difficulty in eliciting real valuations through user studies under hypothetical circumstances. However, our understanding of users' valuations remains limited to specific entities, information types, and levels of realism. We examined the effects of realism and purpose of use on users' valuations of their personal information. Specifically, we conducted an online study in which participants (N=434) were asked to assign monetary value to their personal information in the context of an information marketplace involving different receiving parties, while we experimentally manipulated the level of realism of the scenario and the timing of eliciting valuations. Among our findings is a nuanced understanding of valuation biases, including when they may not apply. For example, we find that, contrary to common belief, participants' valuations are not generally higher in hypothetical scenarios compared to realistic ones. Importantly, we find that while absolute valuations vary greatly between participants, the order in which users prioritize information types (i.e., users' relative valuations of different attributes) remains stable across the levels of realism we study. We discuss how our findings inform system design and future studies.","tags":["Source Themes"],"title":"Comparing Hypothetical and Realistic Privacy Valuations","type":"publication"},{"authors":["Mahmood Sharif","Jumpei Urakawa","Nicolas Christin","Ayumu Kubota","Akira Yamada"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"011f4ffe312b6a7b1a39825bd3ea821f","permalink":"/publication/ccs18-exposure-prediction/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/publication/ccs18-exposure-prediction/","section":"publication","summary":"Many computer-security defenses are reactive---they operate only when security incidents take place, or immediately thereafter. Recent efforts have attempted to predict security incidents before they occur, to enable defenders to proactively protect their devices and networks. These efforts have primarily focused on long-term predictions. We propose a system that enables proactive defenses at the level of a single browsing session. By observing user behavior, it can predict whether they will be exposed to malicious content on the web seconds before the moment of exposure, thus opening a window of opportunity for proactive defenses. We evaluate our system using three months' worth of HTTP traffic generated by 20,645 users of a large cellular provider in 2017 and show that it can be helpful, even when only very low false positive rates are acceptable, and despite the difficulty of making \"on-the-fly\" predictions. We also engage directly with the users through surveys asking them demographic and security-related questions, to evaluate the utility of self-reported data for predicting exposure to malicious content. We find that self-reported data can help forecast exposure risk over long periods of time. However, even on the long-term, self-reported data is not as crucial as behavioral measurements to accurately predict exposure.","tags":["Source Themes"],"title":"Predicting Impending Exposure to Malicious Content from User Behavior","type":"publication"},{"authors":["Mahmood Sharif","Lujo Bauer","Michael K. Reiter"],"categories":null,"content":"","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"ceec68a10e61d1f1cc11136fcfd339b6","permalink":"/publication/cvprw18-lpnorm/","publishdate":"2018-06-01T00:00:00Z","relpermalink":"/publication/cvprw18-lpnorm/","section":"publication","summary":"Much research has been devoted to better understanding adversarial examples, which are specially crafted inputs to machine-learning models that are perceptually similar to benign inputs, but are classified differently (i.e., misclassified). Both algorithms that create adversarial examples and strategies for defending against adversarial examples typically use $L_p$-norms to measure the perceptual similarity between an adversarial input and its benign original. Prior work has already shown, however, that two images need not be close to each other as measured by an $L_p$-norm to be perceptually similar. In this work, we show that nearness according to an $L_p$-norm is not just unnecessary for perceptual similarity, but is also insufficient. Specifically, focusing on datasets (CIFAR10 and MNIST), $L_p$-norms, and thresholds used in prior work, we show through online user studies that \"adversarial examples\" that are closer to their benign counterparts than required by commonly used $L_p$-norm thresholds can nevertheless be perceptually distinct to humans from the corresponding benign examples. Namely, the perceptual distance between two images that are \"near\" each other according to an $L_p$-norm can be high enough that participants frequently classify the two images as representing different objects or digits. Combined with prior work, we thus demonstrate that nearness of inputs as measured by $L_p$-norms is neither necessary nor sufficient for perceptual similarity, which has implications for both creating and defending against adversarial examples. We propose and discuss alternative similarity metrics to stimulate future research in the area.","tags":["Source Themes"],"title":"On the Suitability of $L_p$-norms for Creating and Preventing Adversarial Examples","type":"publication"},{"authors":["William Melicher","Anupam Das","Mahmood Sharif","Lujo Bauer","Limin Jia"],"categories":null,"content":"","date":1517443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517443200,"objectID":"6f4c6c4af654abbafd6e00dd9246192e","permalink":"/publication/ndss18-dom-xss/","publishdate":"2018-02-01T00:00:00Z","relpermalink":"/publication/ndss18-dom-xss/","section":"publication","summary":"Cross-site scripting (XSS) vulnerabilities are the most frequently reported web application vulnerability. As complex JavaScript applications become more widespread, DOM (Document Object Model) XSS vulnerabilities---a type of XSS vulnerability where the vulnerability is located in client-side JavaScript, rather than server-side code---are becoming more common. As the first contribution of this work, we empirically assess the impact of DOM XSS on the web using a browser with taint tracking embedded in the JavaScript engine. Building on the methodology used in a previous study that crawled popular websites, we collect a current dataset of potential DOM XSS vulnerabilities. We improve on the methodology for confirming XSS vulnerabilities, and using this improved methodology, we find 83% more vulnerabilities than previous methodology applied to the same dataset. As a second contribution, we identify the causes of and discuss how to prevent DOM XSS vulnerabilities. One example of our findings is that custom HTML templating designs---a design pattern that could prevent DOM XSS vulnerabilities analogous to parameterized SQL---can be buggy in practice, allowing DOM XSS attacks. As our third contribution, we evaluate the error rates of three static-analysis tools to detect DOM XSS vulnerabilities found with dynamic analysis techniques using in-the-wild examples. We find static-analysis tools to miss 90% of bugs found by our dynamic analysis, though some tools can have very few false positives and at the same time find vulnerabilities not found using the dynamic analysis.","tags":["Source Themes"],"title":"Riding Out DOMsday: Toward Detecting and Preventing DOM Cross-Site Scripting","type":"publication"},{"authors":["Zachary Weinberg","Mahmood Sharif","Janos Szurdi","Nicolas Christin"],"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"96a504ca4004253cb7a86caef5af9614","permalink":"/publication/pets17-censorship/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/publication/pets17-censorship/","section":"publication","summary":"Studies of Internet censorship rely on an experimental technique called probing. From a client within each country under investigation, the experimenter attempts to access network resources that are suspected to be censored, and records what happens. The set of resources to be probed is a crucial, but often neglected, element of the experimental design. We analyze the content and longevity of 758,191 webpages drawn from 22 different probe lists, of which 15 are alleged to be actual blacklists of censored webpages in particular countries, three were compiled using *a priori* criteria for selecting pages with an elevated chance of being censored, and four are controls. We find that the lists have very little overlap in terms of specific pages. Mechanically assigning a topic to each page, however, reveals common themes, and suggests that hand-curated probe lists may be neglecting certain frequently-censored topics. We also find that pages on controversial topics tend to have much shorter lifetimes than pages on uncontroversial topics. Hence, probe lists need to be continuously updated to be useful. To carry out this analysis, we have developed automated infrastructure for collecting snapshots of webpages, weeding out irrelevant material (e.g. site \"boilerplate\" and parked domains), translating text, assigning topics, and detecting topic changes. The system scales to hundreds of thousands of pages collected.","tags":["Source Themes"],"title":"Topics of Controversy: An Empirical Analysis of Web Censorship Lists","type":"publication"},{"authors":["Yukiko Sawaya","Mahmood Sharif","Nicolas Christin","Ayumu Kubota","Akihiro Nakarai","Akira Yamada"],"categories":null,"content":"","date":1493596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493596800,"objectID":"9fff988fb0db8cd8250abeed4a379abb","permalink":"/publication/chi17-cross-cultural-study/","publishdate":"2017-05-01T00:00:00Z","relpermalink":"/publication/chi17-cross-cultural-study/","section":"publication","summary":"Computer security tools usually provide universal solutions without taking user characteristics (origin, income level, ...) into account. In this paper, we test the validity of using such universal security defenses, with a particular focus on culture. We apply the previously proposed Security Behavior Intentions Scale (SeBIS) to 3,500 participants from seven countries. We first translate the scale into seven languages while preserving its reliability and structure validity. We then build a regression model to study which factors affect participants' security behavior. We find that participants from different countries exhibit different behavior. For instance, participants from Asian countries, and especially Japan, tend to exhibit less secure behavior. Surprisingly to us, we also find that actual knowledge influences user behavior much less than user self-confidence in their computer security knowledge. Stated differently, what people think they know affects their security behavior more than what they do know.","tags":["Source Themes"],"title":"Self-Confidence Trumps Knowledge: A Cross-Cultural Study of Security Behavior","type":"publication"},{"authors":["Mahmood Sharif","Sruti Bhagavatula","Lujo Bauer","Michael K. Reiter"],"categories":null,"content":"","date":1475280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475280000,"objectID":"616dd6637b75465ac2d4641ff81e85c2","permalink":"/publication/ccs16-adv-ml/","publishdate":"2016-10-01T00:00:00Z","relpermalink":"/publication/ccs16-adv-ml/","section":"publication","summary":"Machine learning is enabling a myriad innovations, including new algorithms for cancer diagnosis and self-driving cars. The broad use of machine learning makes it important to understand the extent to which machine-learning algorithms are subject to attack, particularly when used in applications where physical security or safety is at risk. In this paper, we focus on facial biometric systems, which are widely used in surveillance and access control. We define and investigate a novel class of attacks: attacks that are *physically realizable* and *inconspicuous*, and allow an attacker to evade recognition or impersonate another individual. We develop a systematic method to automatically generate such attacks, which are realized through printing a pair of eyeglass frames. When worn by the attacker whose image is supplied to a state-of-the-art face-recognition algorithm, the eyeglasses allow her to evade being recognized or to impersonate another individual. Our investigation focuses on white-box face-recognition systems, but we also demonstrate how similar techniques can be used in black-box scenarios, as well as to avoid face *detection*.","tags":["Source Themes"],"title":"Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition","type":"publication"},{"authors":["William Melicher","Mahmood Sharif","Joshua Tan","Lujo Bauer","Mihai Christodorescu","Pedro G. Leon"],"categories":null,"content":"","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467331200,"objectID":"92ce2f20be2bdf18a2a4ceaee05a3558","permalink":"/publication/pets16-online-tracking/","publishdate":"2016-07-01T00:00:00Z","relpermalink":"/publication/pets16-online-tracking/","section":"publication","summary":"Online trackers compile profiles on users for targeting ads, customizing websites, and selling users' information. In this paper, we report on the first detailed study of the perceived benefits and risks of tracking---and the reasons behind them---conducted in the context of users' own browsing histories. Prior work has studied this in the abstract; in contrast, we collected browsing histories from and interviewed 35 people about the perceived benefits and risks of online tracking in the context of their own browsing behavior. We find that many users want more control over tracking and think that controlled tracking has benefits, but are unwilling to put in the effort to control tracking or distrust current tools. We confirm previous findings that users' general attitudes about tracking are often at odds with their comfort in specific situations. We also identify specific situational factors that contribute to users' preferences about online tracking and explore how and why. Finally, we examine a sample of popular tools for controlling tracking and show that they only partially address the situational factors driving users' preferences. We suggest opportunities to improve such tools, and explore the use of a classifier to automatically determine whether a user would be comfortable with tracking on a particular page visit; our results suggest this is a promising direction for future work.","tags":["Source Themes"],"title":"(Do Not) Track Me Sometimes: Users' Contextual Preferences for Web Tracking","type":"publication"}]